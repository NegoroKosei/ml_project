{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fpdNqYJz8MQ"
   },
   "source": [
    "# Simple VisionTransformer\n",
    "\n",
    "2023/10/27 M.Udagawa\n",
    "\n",
    "google colabを想定\n",
    "\n",
    "内容は「Transformer variational wave functions for frustrated quantum spin systems(arXiv:2211.05504v2)」を参照\n",
    "\n",
    "Attentionの理解にはこれで十分かもしれないが、本来のViTとしては位置エンコーダやMLPらへんは省略されている点は注意\n",
    "\n",
    "また現状(2023/10/27)、**このモデルを使ってもボースハバード模型の基底状態は求まらない**。あくまで、Attentionの理解というスタンスで使ってください\n",
    "\n",
    "次の初学者向けのタブは長いので、左端の▽で閉じるべし。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8rKhRiQeQY9"
   },
   "source": [
    "# 以下は初学者向け"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89GZdrHbisCX"
   },
   "source": [
    "## 想定する読者のレベル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vzeOEWPivEA"
   },
   "source": [
    "\n",
    "内容としては以下がわかれば理解できる\n",
    "\n",
    "* ベクトルの内積、行列の積\n",
    "* Pythonでforループができる\n",
    "* Pytorchで全結合ニューラルネットワークが作れる\n",
    "* numpyの操作(reshape, random)\n",
    "* ソフトマックス関数\n",
    "\n",
    "・（ちょい難）ベクトルや行列の計算を成分でできるならAttentionは（数学的に）即座に理解できる->興味がある人は「アインシュタインの縮約記法」で検索、これができるようになると解析力学、ベクトル解析、量子力学などで圧倒的成長を感じられる。なにより便利である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_36nGo9eiZZ_"
   },
   "source": [
    "\n",
    "## コード上のnumとは？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUWtQTGMib0G"
   },
   "source": [
    "詳細はボースハバード模型のコードを参照\n",
    "\n",
    "numは(サンプル,格子点)を表している。なので\n",
    "\n",
    "num[i]\n",
    "\n",
    "は$i$番目のサンプルを意味するベクトルだし、\n",
    "\n",
    "num[i][j]\n",
    "\n",
    "は$i$番目のサンプルの格子点$j$の値を意味する。値とは、例えば、Ising模型ではスピン$\\{\\pm1\\}$、ボースハバード模型ではその格子の粒子数となる。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jp4sgplnie1f"
   },
   "source": [
    "\n",
    "## 論文中ではANNの入力は１つのサンプル=ベクトルになっていたがコード中は全サンプル=行列を代入している。これでいいのか？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T66h9zYNi3xW"
   },
   "source": [
    "\n",
    "問題ない、ようにANNを作ればよい。もちろんベクトルを入力とするようなANNを作って利用することも可能だが、\n",
    "\n",
    "*   コードの行数削減\n",
    "*   計算速度の短縮\n",
    "*   （最重要）動くけど計算は間違いのとき、バグがマジで見つからない\n",
    "\n",
    "といった理由で行列にして明示的に操作する方針を取っている。コードを1行ずつかみ砕いていけば、実際は各サンプルごとに計算しているのがわかるはず。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xb6jfynk0Xgj"
   },
   "source": [
    "# セットアップ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClnzCJta0Z_c"
   },
   "source": [
    "ライブラリのインポート\n",
    "\n",
    "einopsはcolabの初期環境には存在しないため、ランタイム接続時にインストールする必要がある。\n",
    "文頭の!は「これからLinuxコマンドを打つ」宣言に相当する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xkmvCI0aJ7cK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#!pip install einops\n",
    "from einops.layers.torch import Rearrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8q15frpkyERa"
   },
   "source": [
    "初期値の設定\n",
    "\n",
    "下部ではTransformer内部でどんな値になっているか確認できるが、NGが表示されている場合は使えない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Wvwwm9brSctk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "---check---\n",
      "number of patches:  4\n",
      "dimension per head:  1\n"
     ]
    }
   ],
   "source": [
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# n_sample:サンプル数\n",
    "# n_site:サイトの数\n",
    "# num:サンプル(n_sample, n_site)\n",
    "# patch_size:パッチサイズ\n",
    "# n_heads:ヘッドの数\n",
    "# depth:ViTの層の深さ(Attentionのループの回数)\n",
    "#\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "n_sample = 2\n",
    "n_site = 8\n",
    "num = np.ones((n_sample, n_site))\n",
    "patch_size = 2\n",
    "n_heads = 2\n",
    "depth = 1\n",
    "\n",
    "print(num)\n",
    "\n",
    "print('---check---')\n",
    "if n_site % patch_size == 0:\n",
    "  print('number of patches: ', n_site//patch_size)\n",
    "else:\n",
    "  print('patch size: NG')\n",
    "\n",
    "if patch_size % n_heads == 0:\n",
    "  print('dimension per head: ', patch_size//n_heads)\n",
    "else:\n",
    "  print('number of heads: NG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzOmk4v8siMI"
   },
   "source": [
    "デバイスの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9s8V1cnSsh-7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNL0EizN0-o1"
   },
   "source": [
    "# パッチ分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kRsIDfisgMC"
   },
   "source": [
    "インプットとなる粒子数の配置は次のような形になっている\n",
    "\n",
    "$ input = \\begin{bmatrix} \\mathbf{n}_1 = [0, 2, \\dots ,1] \\\\ \\mathbf{n}_2  = [1, 1, \\dots 0]\\\\ \\vdots \\\\ \\mathbf{n}_{{n_{sample}}}=[2,1,\\dots 1] \\end{bmatrix}$\n",
    "\n",
    "$input.shape = [n_{sample}, n_{site}]$\n",
    "\n",
    "この中から一つのサンプルを取り出してみる、例えば$n_{site}=4$なら\n",
    "\n",
    "$\\mathbf{n}_i = [2,0,1,1]$\n",
    "\n",
    "パッチ分割というのは、これを等分していくつかのベクトルに分けるということである。例えばパッチサイズが2なら\n",
    "\n",
    "$\\mathbf{n_i} -> [2, 0], [1, 1] $\n",
    "\n",
    "これを全てのサンプルに対して行うと\n",
    "\n",
    "$input.shape \\rightarrow x.shape= [n_{sample},n_{patches}, patch\\ size]$\n",
    "\n",
    "ただし、$n_{pathces}$は$n_{site} = patch\\ size \\times n_{patches}$ をみたす正整数でなければならない。\n",
    "\n",
    "自然言語処理でいうならばこの一つのパッチが単語に相当しており、それゆえパッチ分割は後述のAttentionのために必須の操作である。\n",
    "\n",
    "また、torch.tensorの配列の操作として、einopsライブラリのRearrangeを使うと便利らしく、実際以下では頻繁に利用する（torch.reshapeでも対応できるかはやってみないと分からないが、現時点(2023/10/20)でRearrangeに不満はない）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1698407844639,
     "user": {
      "displayName": "Manato Udagawa",
      "userId": "00594879605715177890"
     },
     "user_tz": -540
    },
    "id": "FcbvNNypaDU6"
   },
   "outputs": [],
   "source": [
    "class Patching(nn.Module):\n",
    "  def __init__(self, patch_size):\n",
    "    super().__init__()\n",
    "\n",
    "    # inputのshapeは(n_sample, n_site)\n",
    "    # n_site = patch_size * n_patches (definition of n_patches(int))\n",
    "    # そこで次の変換をする\n",
    "    # (n_sample, n_site) -> (n_sample, n_patches, patch_size)\n",
    "    # s:n_sample, np:n_patches, ps:patch_size\n",
    "\n",
    "    self.new_input = Rearrange('s (np ps) ->s np ps', ps=patch_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    output = self.new_input(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khmyJCB-1_YL"
   },
   "source": [
    "動かしてみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "PwCwJVW6Sxg6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "num = np.ones((n_sample, n_site))\n",
    "model = Patching(patch_size)\n",
    "num = model(num)\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCosMnaf1BjF"
   },
   "source": [
    "# アテンション機構"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBMxHIA1y48R"
   },
   "source": [
    "早速本題である。以下では、簡単のため議論上はサンプル数1として考える(コードは$n_{sample}$)。\n",
    "\n",
    "パッチ分割により、この部分への入力は\n",
    "\n",
    "$x.shape = [n_{patches}, patch\\ size] $\n",
    "\n",
    "となっている。すなわち、粒子数分布(１個の$n_{site}$次元ベクトル)を$n_{patches}$個の$patch\\ size$次元ベクトルに分割されている。\n",
    "\n",
    "$\\mathbf{n}_i = [2,0,1,1] -> [2, 0], [1, 1] = \\mathbf{x_1}, \\mathbf{x_2}$\n",
    "\n",
    "この一つ一つのベクトルから、さらに3個ずつベクトルを生成する。\n",
    "\n",
    "$\\mathbf{q}_i = W_q\\mathbf{x}_i$\n",
    "\n",
    "$\\mathbf{k}_i = W_k\\mathbf{x}_i$\n",
    "\n",
    "$\\mathbf{v}_i = W_v\\mathbf{x}_i, (W_\\nu.shape = [patch\\ size, patch\\ size],\\mu = q,k,v)$\n",
    "\n",
    "なお重み$W_\\mu$は一般的に全結合ネットワーク一層に相当する。\n",
    "\n",
    "これらは順にクエリquery、キーkey、バリューvalueという。これらによって、アテンションは次のように定義される\n",
    "\n",
    "$\\mathbf{A}_i = \\sum_j Softmax(\\frac{\\mathbf{q}_i\\cdot \\mathbf{k}_j}{\\sqrt{d}}) \\mathbf{v}_j$\n",
    "\n",
    "一つ一つ順を追って説明しよう。まず、ソフトマックスの中にある内積に注目する。\n",
    "\n",
    "$\\mathbf{q}_i\\cdot\\mathbf{k}_j$\n",
    "\n",
    "これらのベクトルの添え字はもともとパッチの場所を指定していたことを思い出そう。するとこれは、パッチとパッチの間の関係、すなわち長距離相関を捉えている(逆に一つ一つのベクトルq,k,vはあるパッチの情報、すなわち局所的な特徴を捉えている)。\n",
    "\n",
    "とはいえこの時点では二つのパッチ（2単語）の関係しか言えない。うまいこと系全体（文章）の特徴を捉えた量に変換出来ないだろうか。\n",
    "\n",
    "ここでもう一度添え字に着目すると内積$\\mathbf{q}_i\\cdot\\mathbf{k}_j$は二つの添え字$(i,j)$で定まる。これをもう少し俯瞰してみる。すなわち、二つの添え字$(i,j)$で定まるものといえば行列の成分があったことを思い出す。このような異なる添え字のついたもの同士の積は一般的に行列として扱う（当然添え字が3つ以上も可能、その場合は多次元配列となる）。\n",
    "\n",
    "この行列とすべてのバリュー$\\mathbf{v}_i$を使えば、系全体(文章)の特徴を取り入れた新しいパッチ(単語の抽象版?)を$n_{patches}$個作れそうである。\n",
    "\n",
    "$\\mathbf{A}_i \\overset{?}{=} \\sum_j (\\mathbf{q}_i\\cdot\\mathbf{k}_j) \\mathbf{v}_j$\n",
    "\n",
    "ただしこのままの定義だと行列の要素が極端に大きくなり特定のパッチからの影響を強く受ける可能性がある。だからソフトマックスを使って0以上1以下の数値に規格化している。なお、ソフトマックス関数の規格化は$\\mathbf{k}_j$の添え字$j$についてとる。この部分の構造は頻繁に使われるため、Attention weight $\\alpha_{ij}$としてよく書かれる。\n",
    "\n",
    "$\\alpha_{ij} = Softmax(\\frac{\\mathbf{q}_i\\cdot\\mathbf{k}_j}{\\sqrt{d}})$\n",
    "\n",
    "また、アテンションは入力と全く同じ構造をしている。\n",
    "\n",
    "$[\\mathbf{x}_i].shape = [\\mathbf{A}_i].shape = [n_{patches}, patch\\ size]$\n",
    "\n",
    "そのため、出力を再度入力としてループさせることが可能である。本来のViTでは残差接続を活用して深層化しているようだ。\n",
    "\n",
    "以上がアテンションの概要である。\n",
    "\n",
    "実際のプログラムではheadというものを使っているが、本質的にはあまり変わらない（イメージ的にはパッチの中の同じ部分ごとにAttentionを計算している）。Rearrangeを最初と最後にしているだけなので、コードを見て理解するのが速いだろう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1698407849988,
     "user": {
      "displayName": "Manato Udagawa",
      "userId": "00594879605715177890"
     },
     "user_tz": -540
    },
    "id": "BkCzgRIwaJRQ"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "  def __init__(self, patch_size, n_heads):\n",
    "    super().__init__()\n",
    "    #\n",
    "    # input(n_sample, n_patches, patch_size)\n",
    "    # self.dim_heads:一つのヘッドに与えられるベクトルの長さ\n",
    "    #\n",
    "    self.n_heads = n_heads\n",
    "    self.dim_heads = patch_size//n_heads\n",
    "\n",
    "    super().__init__()\n",
    "\n",
    "    self.W_Q = nn.Linear(patch_size, patch_size, bias=False)\n",
    "    self.W_K = nn.Linear(patch_size, patch_size, bias=False)\n",
    "    self.W_V = nn.Linear(patch_size, patch_size, bias=False)\n",
    "\n",
    "    self.split_into_heads = Rearrange(\"s np (nh dh) -> s nh np dh\", nh = self.n_heads)\n",
    "\n",
    "    self.softmax = nn.Softmax(dim = -1)\n",
    "\n",
    "    self.concat = Rearrange(\"s nh np dh -> s np (nh dh)\", nh = self.n_heads)\n",
    "\n",
    "  def forward(self, x):\n",
    "    #\n",
    "    # x == input:(n_sample, n_patches, patch_size)\n",
    "    # q,k,v != input:(n_sample, n_patches, patch_size)\n",
    "    # q,k,v in head:(n_sample, n_heads, n_patches, dim_heads)\n",
    "    # k.transpose(-1, -2):(n_sample, n_heads, dim_heads, n_patches)\n",
    "    # matmulは第一引数の最後尾と第二引数の最後尾から２個目のサフィックスの行列積\n",
    "    # logit, attention_weight:(n_sample, n_heads, n_patches, n_patches)\n",
    "    # output before concat:(n_sample, n_heads, n_patches, dim_heads)\n",
    "    # output :(n_sample, n_patches, patch_size)\n",
    "    #\n",
    "    q = self.W_Q(x)\n",
    "    k = self.W_K(x)\n",
    "    v = self.W_V(x)\n",
    "\n",
    "    q = self.split_into_heads(q)\n",
    "    k = self.split_into_heads(k)\n",
    "    v = self.split_into_heads(v)\n",
    "\n",
    "    logit = torch.matmul(q, k.transpose(-1, -2)) * (self.dim_heads ** -0.5)\n",
    "    attention_weight = self.softmax(logit)\n",
    "\n",
    "    output = torch.matmul(attention_weight, v)\n",
    "    output = self.concat(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkAT6Xlpk-g5"
   },
   "source": [
    "## torch.matmulの確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nw26fR_nkerb"
   },
   "source": [
    "まずはベクトルから\n",
    "\n",
    "$ \\mathbf{q}\\cdot\\mathbf{k} = \\sum_i q_ik_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "1VMhZ3-ejC3O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q= tensor([0, 1, 2]) torch.Size([3])\n",
      "k= tensor([0, 1, 2]) torch.Size([3])\n",
      "torch.matmul(q, k) =  tensor(5)\n",
      "torch.matmul(k, q) =  tensor(5)\n"
     ]
    }
   ],
   "source": [
    "#確認用(check)\n",
    "q_ = torch.arange(3)\n",
    "k_ = torch.arange(3)\n",
    "print('q=', q_, q_.shape)\n",
    "print('k=', k_, k_.shape)\n",
    "print('torch.matmul(q, k) = ',torch.matmul(q_, k_))\n",
    "print('torch.matmul(k, q) = ',torch.matmul(k_, q_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAvLzphFlpXy"
   },
   "source": [
    "$Q= \\begin{pmatrix}1&0&0 \\\\ 0&1&0\\end{pmatrix}, K = \\begin{pmatrix}0& 1&2 \\\\ 3 & 4&5\\end{pmatrix}$\n",
    "\n",
    "$Q.shape=[2\\times3], K.shape=[2\\times3]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "o1wPGEGElCad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q= tensor([[1, 0, 0],\n",
      "        [0, 1, 0]]) torch.Size([2, 3])\n",
      "K= tensor([[0, 1, 2],\n",
      "        [3, 4, 5]]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "Q_ = torch.tensor([[1,0,0],[0,1,0]])\n",
    "print(\"Q=\", Q_, Q_.shape)\n",
    "K_ = torch.arange(6)\n",
    "K_ = torch.reshape(K_, (2,3))\n",
    "print(\"K=\",K_, K_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "kycLZxgbm8Ut"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x3 and 2x3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ysdno\\OneDrive\\デスクトップ\\Machine Learning\\セミナー\\後期\\pytorch\\(配布用)SimpleViT.ipynb セル 29\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ysdno/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/Machine%20Learning/%E3%82%BB%E3%83%9F%E3%83%8A%E3%83%BC/%E5%BE%8C%E6%9C%9F/pytorch/%28%E9%85%8D%E5%B8%83%E7%94%A8%29SimpleViT.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39;49mmatmul(Q_, K_))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x3 and 2x3)"
     ]
    }
   ],
   "source": [
    "print(torch.matmul(Q_, K_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27qgTy-Yp3pY"
   },
   "source": [
    "$K^T.shape=[3\\times2]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "IaJXzsAjo61B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 3],\n",
      "        [1, 4]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.matmul(Q_, K_.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "xO0g4MUnmSCd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n"
     ]
    }
   ],
   "source": [
    "print(K_.T)\n",
    "print(K_.transpose(0, 1))\n",
    "print(K_.transpose(1, 0))\n",
    "#transposeの引数は転置したい二つのaxisを選んでいる\n",
    "#順番は関係ない？\n",
    "print(K_.transpose(-1, -2))\n",
    "print(K_.transpose(-2, -1))\n",
    "#dimの指定におけるマイナスは、最後尾から何番目の配列を表す。\n",
    "#2次元配列の場合は,[0=-2], [1=-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3seQ1KqrOXd"
   },
   "source": [
    "ここから本題\n",
    "\n",
    "$q.shape=k.shape=[n_{sample}, n_{heads}, n_{patch}, dim_{head}]$\n",
    "\n",
    "headの中の話だから、前二つは無関係"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "nPaOP09yd_9p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q= torch.Size([2, 2, 4, 1])\n",
      "k= torch.Size([2, 2, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "#確認用(check)\n",
    "q_ = torch.arange(n_sample*n_heads*(n_site//patch_size)*(patch_size//n_heads))\n",
    "q_ = q_.reshape((n_sample, n_heads, n_site//patch_size, patch_size//n_heads))\n",
    "print('q=', q_.shape)\n",
    "k_ = torch.arange(n_sample*n_heads*(n_site//patch_size)*(patch_size//n_heads))\n",
    "k_ = k_.reshape((n_sample, n_heads, n_site//patch_size, patch_size//n_heads))\n",
    "print('k=', k_.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Sb9WxrvmrqEX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k.transpose= torch.Size([2, 2, 1, 4])\n",
      "logit= tensor([[[[  0,   0,   0,   0],\n",
      "          [  0,   1,   2,   3],\n",
      "          [  0,   2,   4,   6],\n",
      "          [  0,   3,   6,   9]],\n",
      "\n",
      "         [[ 16,  20,  24,  28],\n",
      "          [ 20,  25,  30,  35],\n",
      "          [ 24,  30,  36,  42],\n",
      "          [ 28,  35,  42,  49]]],\n",
      "\n",
      "\n",
      "        [[[ 64,  72,  80,  88],\n",
      "          [ 72,  81,  90,  99],\n",
      "          [ 80,  90, 100, 110],\n",
      "          [ 88,  99, 110, 121]],\n",
      "\n",
      "         [[144, 156, 168, 180],\n",
      "          [156, 169, 182, 195],\n",
      "          [168, 182, 196, 210],\n",
      "          [180, 195, 210, 225]]]]) torch.Size([2, 2, 4, 4])\n",
      "output= tensor([[[[    0],\n",
      "          [   14],\n",
      "          [   28],\n",
      "          [   42]],\n",
      "\n",
      "         [[  504],\n",
      "          [  630],\n",
      "          [  756],\n",
      "          [  882]]],\n",
      "\n",
      "\n",
      "        [[[ 2928],\n",
      "          [ 3294],\n",
      "          [ 3660],\n",
      "          [ 4026]],\n",
      "\n",
      "         [[ 8808],\n",
      "          [ 9542],\n",
      "          [10276],\n",
      "          [11010]]]]) torch.Size([2, 2, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "print('k.transpose=',k_.transpose(-1,-2).shape)\n",
    "logit_ = torch.matmul(q_, k_.transpose(-1,-2))\n",
    "print('logit=',logit_, logit_.shape)\n",
    "output_ = torch.matmul(logit_, q_)\n",
    "print('output=', output_, output_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtrCDDjGz0II"
   },
   "source": [
    "## 実際に動かす"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGzgVmJH0DSo"
   },
   "source": [
    "流れを確認するため、それまでのクラスをすべて使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "vyqdn2ykkfYT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.61085075 0.67732286]\n",
      "  [0.61085075 0.67732286]\n",
      "  [0.61085075 0.67732286]\n",
      "  [0.61085075 0.67732286]]\n",
      "\n",
      " [[0.61085075 0.67732286]\n",
      "  [0.61085075 0.67732286]\n",
      "  [0.61085075 0.67732286]\n",
      "  [0.61085075 0.67732286]]]\n"
     ]
    }
   ],
   "source": [
    "num = np.ones((n_sample, n_site))\n",
    "model = Patching(patch_size)\n",
    "model = model.to(device)\n",
    "num = model(num)\n",
    "\n",
    "model = Attention(patch_size, n_heads)\n",
    "model = model.to(device)\n",
    "num = torch.from_numpy(num.astype(np.float32)).detach().to(device)\n",
    "num = model(num)\n",
    "num = num.to('cpu').detach().numpy().copy()\n",
    "print(num)\n",
    "#変換時の末尾のclone(),copy()について\n",
    "#numpyとtorch.tensorはメモリを共有しているため、明示的に書いておくべし"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "US_IzdkBJ9xB"
   },
   "source": [
    "# Transformer Encoder\n",
    "\n",
    "基本的には以下のループ\n",
    "\n",
    "Attention -> 全結合層 -> 活性化関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1698407873854,
     "user": {
      "displayName": "Manato Udagawa",
      "userId": "00594879605715177890"
     },
     "user_tz": -540
    },
    "id": "UKZOFg8eqFzw"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self, depth, n_heads):\n",
    "    super().__init__()\n",
    "    self.depth = depth\n",
    "\n",
    "    self.Attention = Attention(patch_size, n_heads)\n",
    "\n",
    "    self.W = nn.Linear(patch_size, patch_size, bias=False)\n",
    "\n",
    "    #self.nonlinear = nn.functional.relu()\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    for _ in range(self.depth):\n",
    "      output = self.Attention(x)\n",
    "      output = self.W(output)\n",
    "      output = nn.functional.relu(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "v17gj4AeByto"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4, 2)\n",
      "[[[0.05886333 0.        ]\n",
      "  [0.05886333 0.        ]\n",
      "  [0.05886333 0.        ]\n",
      "  [0.05886333 0.        ]]\n",
      "\n",
      " [[0.05886333 0.        ]\n",
      "  [0.05886333 0.        ]\n",
      "  [0.05886333 0.        ]\n",
      "  [0.05886333 0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "num = np.ones((n_sample, n_site))\n",
    "model = Patching(patch_size)\n",
    "model = model.to(device)\n",
    "num = model(num)\n",
    "\n",
    "###ここから\n",
    "model = Encoder(depth, n_heads)\n",
    "model = model.to(device)\n",
    "num = torch.from_numpy(num.astype(np.float32)).detach().to(device)\n",
    "num = model(num)\n",
    "num = num.to('cpu').detach().numpy().copy()\n",
    "print(num.shape)\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlDgn_4mKbec"
   },
   "source": [
    "# ViT\n",
    "\n",
    "上記を順番に行うだけ。\n",
    "\n",
    "最後にパッチ分割した分の配列の変化を元に戻して、和を取る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1698407897142,
     "user": {
      "displayName": "Manato Udagawa",
      "userId": "00594879605715177890"
     },
     "user_tz": -540
    },
    "id": "0_JGdoePSlSZ"
   },
   "outputs": [],
   "source": [
    "class SimpleViT(nn.Module):\n",
    "  def __init__(self, patch_size, depth, n_heads):\n",
    "    #\n",
    "    # n_patches:サイトをパッチで分割したときのパッチの数\n",
    "    #\n",
    "    super().__init__()\n",
    "\n",
    "    self.n_pathces = n_site//patch_size\n",
    "\n",
    "    self.Patching = Patching(patch_size)\n",
    "\n",
    "    self.Encoder = Encoder(depth, n_heads)\n",
    "\n",
    "    self.output_concat = Rearrange('s np ps -> s (np ps)', np = self.n_pathces, ps = patch_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    output = self.Patching(x)\n",
    "    output = self.Encoder(output)\n",
    "    output = self.output_concat(output)\n",
    "    output = output.sum(axis=1)\n",
    "    return output\n",
    "  def forward_cpu(self, x):\n",
    "    output = torch.from_numpy(x.astype(np.float32)).detach().to(device)\n",
    "    with torch.no_grad():\n",
    "      output = self.forward(output)\n",
    "    return output.to('cpu').detach().numpy().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "VuLc_ig4yZFP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---check---\n",
      "number of patches:  8\n",
      "dimension per head:  1\n"
     ]
    }
   ],
   "source": [
    "n_sample = 10\n",
    "n_site = 16\n",
    "\n",
    "print('---check---')\n",
    "if n_site % patch_size == 0:\n",
    "  print('number of patches: ', n_site//patch_size)\n",
    "else:\n",
    "  print('patch size: NG')\n",
    "\n",
    "if patch_size % n_heads == 0:\n",
    "  print('dimension per head: ', patch_size//n_heads)\n",
    "else:\n",
    "  print('number of heads: NG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ua-UowxPIMTC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.87816168 0.41624672 0.48155183 0.78003703 0.17704251 0.87117052\n",
      "  0.20424827 0.03577197 0.44510434 0.46343343 0.0723286  0.8872842\n",
      "  0.95904707 0.70279473 0.81886196 0.32598124]\n",
      " [0.72262004 0.02262676 0.74661716 0.44918226 0.4250344  0.72004776\n",
      "  0.76506545 0.80493129 0.49840751 0.89695819 0.81188344 0.39618581\n",
      "  0.19586283 0.49521393 0.47046149 0.23265885]\n",
      " [0.00376722 0.83925521 0.66545875 0.87280518 0.48819191 0.35069221\n",
      "  0.46086927 0.09706341 0.84181032 0.60396023 0.69491252 0.80531268\n",
      "  0.76083781 0.06311449 0.12271661 0.60432016]\n",
      " [0.58882927 0.5511036  0.98911951 0.55643325 0.47431307 0.2937042\n",
      "  0.14305036 0.03704857 0.77399822 0.03706575 0.97072502 0.62036086\n",
      "  0.74600643 0.73861576 0.91583704 0.38125537]\n",
      " [0.53606336 0.41859981 0.17305056 0.2441288  0.13758955 0.44218887\n",
      "  0.81361087 0.06360193 0.01875181 0.53764703 0.94714106 0.61738377\n",
      "  0.28533387 0.78479613 0.28682383 0.58152511]\n",
      " [0.01015564 0.1843535  0.22468013 0.14565312 0.36030343 0.28948403\n",
      "  0.49135017 0.19143105 0.00484126 0.26906513 0.09176641 0.64552895\n",
      "  0.83157413 0.14203045 0.07562315 0.50223408]\n",
      " [0.77359961 0.70355341 0.76231751 0.12679914 0.89530089 0.48281545\n",
      "  0.844584   0.56737265 0.58786075 0.30115942 0.27290232 0.62783111\n",
      "  0.21663871 0.68970157 0.80651309 0.53635759]\n",
      " [0.93210224 0.03409239 0.41880209 0.6549908  0.13789599 0.43850335\n",
      "  0.56675248 0.40618532 0.27666505 0.53523722 0.50456255 0.1185228\n",
      "  0.22871532 0.96927396 0.9274819  0.95170481]\n",
      " [0.16180068 0.22762075 0.58507261 0.82687732 0.23885969 0.96466428\n",
      "  0.44710442 0.79665445 0.06932472 0.32181205 0.70441366 0.26247946\n",
      "  0.23893001 0.61807896 0.91826392 0.96922985]\n",
      " [0.89127272 0.3772179  0.42555518 0.33668584 0.02072171 0.07743546\n",
      "  0.44623187 0.51861959 0.49101809 0.2033182  0.20785703 0.19703906\n",
      "  0.64850232 0.63503089 0.39795821 0.63980119]]\n",
      "(10,)\n",
      "[3.0757856 3.1326823 2.9820154 3.231201  2.4895844 1.610801  3.3450346\n",
      " 2.920134  2.9886816 2.3668628]\n"
     ]
    }
   ],
   "source": [
    "num = np.random.rand(n_sample, n_site)\n",
    "print(num)\n",
    "model = SimpleViT(patch_size=patch_size, depth=depth, n_heads=n_heads)\n",
    "model = model.to(device)\n",
    "output = model.forward_cpu(num)\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNC3cRpKuDyKWXipkGAtDF2",
   "provenance": [
    {
     "file_id": "1ZuyrWzF8uqfL3U9D2pw1u8IBDEQeFr0b",
     "timestamp": 1697795496554
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
